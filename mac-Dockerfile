# Base image from https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/docker/
FROM arm64v8/flink:1.20.0-scala_2.12-java17

# Container environment variable(s)
ENV PYTHON_VERSION=3.11
ENV PYTHON_PATCH=.9
ENV PYTHON_VERION_WITH_PATCH=${PYTHON_VERSION}${PYTHON_PATCH}

# Container metadata
LABEL maintainer="j3@thej3.com" \
      description="Apache Flink 1.20 container with Python 3.11.9 installed."

# Install Python dependencies and whatever utilities are needed to install Python from source
# Install libbz2-dev, a development package for the bzip2 library (libbz2), which is used for compressing and decompressing data using the Burrows-Wheeler block-sorting text compression algorithm and Huffman coding.
# Install libffi-dev, a development package for the libffi library, which provides a portable, high-level programming interface to various calling conventions.
# Install libssl-dev, a development package for the OpenSSL library, which is a general-purpose cryptography library that provides an open-source implementation of the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols.
# Install zlib1g-dev, a development package for the zlib library, which is a software library used for data compression.
# Install openjdk-17-jdk-headless, a headless version of the OpenJDK 17 Java Development Kit (JDK) that does not include any graphical user interface (GUI) libraries or tools.
RUN apt-get update && apt-get install -y \
    build-essential \
    openjdk-17-jdk-headless \
    zlib1g-dev \
    libbz2-dev \
    libpq-dev \
    libncurses5-dev \
    libgdbm-dev \
    liblzma-dev \
    libnss3-dev \
    libssl-dev \
    libsqlite3-dev \
    libreadline-dev \
    libffi-dev \
    wget \
    git \
    python3-pip \
    python3-venv

# Install Python from source
RUN cd /usr/local && \
    wget https://www.python.org/ftp/python/${PYTHON_VERION_WITH_PATCH}/Python-${PYTHON_VERION_WITH_PATCH}.tgz && \
    tar -xf Python-${PYTHON_VERION_WITH_PATCH}.tgz && \
    cd Python-${PYTHON_VERION_WITH_PATCH} && \
    ./configure --enable-optimizations && \
    make -j$(nproc) && \
    make altinstall

# Create a symbolic link to the Python 3.11.9 binary
RUN ln -s /usr/local/Python-3.11.9 /usr/bin/python

# Set the PATH environment variable with the path to the Python 3.11.9 binary
ENV PATH="/usr/local/Python-3.11.9:${PATH}"

# Set JAVA_HOME
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-arm64

# ---
# Download JARs to FLINK_HOME/lib to make them available to Flink
# ---
# --- Iceberg Flink Library
RUN curl -L https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-flink-runtime-1.19/1.6.1/iceberg-flink-runtime-1.19-1.6.1.jar -o /opt/flink/lib/iceberg-flink-runtime-1.19-1.6.1.jar

# --- Hive Flink Library
RUN curl -L https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-hive-3.1.3_2.12/1.20.0/flink-sql-connector-hive-3.1.3_2.12-1.20.0.jar -o /opt/flink/lib/flink-sql-connector-hive-3.1.3_2.12-1.20.0.jar

# --- Hadoop Common Classes
RUN curl -L https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/3.4.0/hadoop-common-3.4.0.jar -o /opt/flink/lib/hadoop-common-3.4.0.jar

# --- Hadoop AWS Classes
RUN curl -L https://repo.maven.apache.org/maven2/org/apache/flink/flink-shaded-hadoop-2-uber/2.8.3-10.0/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar -o /opt/flink/lib/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar 

# --- AWS Bundled Classes
RUN curl -L https://repo1.maven.org/maven2/software/amazon/awssdk/bundle/2.27.9/bundle-2.27.9.jar -o /opt/flink/lib/bundle-2.27.9.jar

# Install Nano to edit files
RUN apt update && apt install -y nano

# Install PyFlink, PyIceberg, AWS SDK, and other Python dependencies
RUN python3.11 -m pip install --upgrade pip
RUN python3.11 -m pip install pipenv
RUN python3.11 -m venv .venv
RUN . .venv/bin/activate
RUN pipenv --python 3.11 install "grpcio-tools>=1.29.0,<=1.50.0"
RUN pipenv --python 3.11 install setuptools>=37.0.0
RUN pipenv --python 3.11 install apache-flink==1.20.0
RUN pipenv --python 3.11 install pyiceberg
RUN pipenv --python 3.11 install boto3
RUN pipenv --python 3.11 install s3fs
RUN pipenv --python 3.11 install google-api-python-client
RUN pipenv --python 3.11 install pyflink
RUN pipenv --python 3.11 install py4j==0.10.9.7

# This action forces the installation of the latest version of the AWS SDK and PyFlink
RUN pip install boto3
RUN pip install apache-flink==1.20.0
RUN pip install pyflink
RUN pip install google-api-python-client
#
RUN pip install google-api-python-client

# Set the entrypoint to Flink's entrypoint script
ENTRYPOINT ["/docker-entrypoint.sh"]
